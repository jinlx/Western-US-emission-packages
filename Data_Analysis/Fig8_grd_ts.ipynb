{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8176cace-330e-4760-891f-7e7e4a03a24b",
   "metadata": {},
   "source": [
    "## Ground site data: model vs obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5147ca6-4516-4493-a91b-412dd5bff6a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "This script is used to plot the time series of ground site data from observation and model output.\n",
    "#### This doesn't work for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216ad65c-f8bc-4034-9183-97f921e4f53a",
   "metadata": {},
   "source": [
    "There is a very interesing instruction may be useful for GCv13 output\n",
    "http://danielrothenberg.com/gcpy/tutorials/xarray_overview.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21954aec-8cc4-4059-999e-a57333f40771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import DateFormatter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f11714a-18d2-482e-b418-50c57c304455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable chained assignments\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae01dd0-dfc9-43d1-acc2-6e1644183d3b",
   "metadata": {},
   "source": [
    "### Read observation data in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c207d1d5-a1bb-4a6d-907b-fa3012b1a8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file directory\n",
    "obs_dir = '/glade/work/lixujin/ground'\n",
    "obs_subdir ='/'\n",
    "file = obs_dir+obs_subdir+'grdsites_CO_2018.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f569388c-4af1-43d4-b9ac-28dfda557a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DDHH GMT</th>\n",
       "      <th>Boise_Eastman CO ppm</th>\n",
       "      <th>StLukes Meridian CO ppm</th>\n",
       "      <th>StLukes Meridian PM25 ugm3</th>\n",
       "      <th>MBO_CO_ppbv</th>\n",
       "      <th>MBO_PM1_ug/m3</th>\n",
       "      <th>Chico_CO_ppbv</th>\n",
       "      <th>Chico_CO_MDL</th>\n",
       "      <th>Fresno_CO_ppbv</th>\n",
       "      <th>Fresno_CO_MDL</th>\n",
       "      <th>...</th>\n",
       "      <th>Stockton_MDL</th>\n",
       "      <th>Reno_CO</th>\n",
       "      <th>Reno_MDL</th>\n",
       "      <th>King_CO</th>\n",
       "      <th>King_MDL</th>\n",
       "      <th>Denver_CO</th>\n",
       "      <th>Denver_MDL</th>\n",
       "      <th>Ada_CO</th>\n",
       "      <th>Ada_MDL</th>\n",
       "      <th>Missoula_CO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7/22/2018 0:00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.16</td>\n",
       "      <td>7</td>\n",
       "      <td>103.19</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7/22/2018 1:00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.17</td>\n",
       "      <td>9</td>\n",
       "      <td>102.62</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7/22/2018 2:00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.17</td>\n",
       "      <td>10</td>\n",
       "      <td>102.87</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7/22/2018 3:00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.14</td>\n",
       "      <td>7</td>\n",
       "      <td>104.82</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7/22/2018 4:00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.14</td>\n",
       "      <td>4</td>\n",
       "      <td>103.54</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7/22/2018 5:00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2</td>\n",
       "      <td>105.87</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7/22/2018 6:00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-999</td>\n",
       "      <td>105.71</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7/22/2018 7:00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.12</td>\n",
       "      <td>7</td>\n",
       "      <td>106.71</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>7/22/2018 8:00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6</td>\n",
       "      <td>104.67</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>7/22/2018 9:00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6</td>\n",
       "      <td>104.38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DDHH GMT  Boise_Eastman CO ppm  StLukes Meridian CO ppm  \\\n",
       "0  7/22/2018 0:00                   0.4                     0.16   \n",
       "1  7/22/2018 1:00                   0.4                     0.17   \n",
       "2  7/22/2018 2:00                   0.4                     0.17   \n",
       "3  7/22/2018 3:00                   0.5                     0.14   \n",
       "4  7/22/2018 4:00                   0.4                     0.14   \n",
       "5  7/22/2018 5:00                   0.4                     0.12   \n",
       "6  7/22/2018 6:00                   0.5                     0.11   \n",
       "7  7/22/2018 7:00                   0.4                     0.12   \n",
       "8  7/22/2018 8:00                   0.4                     0.10   \n",
       "9  7/22/2018 9:00                   0.4                     0.10   \n",
       "\n",
       "   StLukes Meridian PM25 ugm3  MBO_CO_ppbv  MBO_PM1_ug/m3  Chico_CO_ppbv  \\\n",
       "0                           7       103.19            1.6          0.144   \n",
       "1                           9       102.62            1.5          0.152   \n",
       "2                          10       102.87            1.5          0.163   \n",
       "3                           7       104.82            1.6          0.169   \n",
       "4                           4       103.54            1.6          0.164   \n",
       "5                           2       105.87            1.5          0.144   \n",
       "6                        -999       105.71            1.3          0.135   \n",
       "7                           7       106.71            1.2          0.148   \n",
       "8                           6       104.67            1.1          0.137   \n",
       "9                           6       104.38            1.0          0.124   \n",
       "\n",
       "   Chico_CO_MDL  Fresno_CO_ppbv  Fresno_CO_MDL  ...  Stockton_MDL  Reno_CO  \\\n",
       "0          0.02           0.164          0.011  ...          0.02    0.227   \n",
       "1          0.02           0.155          0.011  ...          0.02    0.177   \n",
       "2          0.02           0.143          0.011  ...          0.02    0.178   \n",
       "3          0.02           0.162          0.011  ...          0.02    0.233   \n",
       "4          0.02           0.156          0.011  ...          0.02    0.287   \n",
       "5          0.02           0.139          0.011  ...          0.02    0.438   \n",
       "6          0.02           0.131          0.011  ...          0.02    0.306   \n",
       "7          0.02           0.128          0.011  ...          0.02    0.402   \n",
       "8          0.02           0.127          0.011  ...          0.02    0.468   \n",
       "9          0.02           0.125          0.011  ...          0.02    0.426   \n",
       "\n",
       "   Reno_MDL  King_CO  King_MDL  Denver_CO  Denver_MDL  Ada_CO  Ada_MDL  \\\n",
       "0      0.02    0.124      0.02      0.222        0.04   0.142     0.02   \n",
       "1      0.02    0.135      0.02      0.283        0.04   0.162     0.02   \n",
       "2      0.02    0.127      0.02      0.360        0.04   0.177     0.02   \n",
       "3      0.02    0.148      0.02      0.413        0.04   0.172     0.02   \n",
       "4      0.02    0.187      0.02      0.274        0.04   0.148     0.02   \n",
       "5      0.02    0.221      0.02      0.216        0.04   0.149     0.02   \n",
       "6      0.02    0.200      0.02      0.279        0.04   0.129     0.02   \n",
       "7      0.02    0.146      0.02      0.337        0.04   0.115     0.02   \n",
       "8      0.02    0.132      0.02      0.257        0.04   0.121     0.02   \n",
       "9      0.02    0.116      0.02      0.246        0.04   0.106     0.02   \n",
       "\n",
       "   Missoula_CO  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "5          NaN  \n",
       "6          NaN  \n",
       "7          NaN  \n",
       "8          NaN  \n",
       "9          NaN  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in csv data\n",
    "df = pd.read_csv(file)#,header=0,index_col=0)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdc28aec-3fec-4ca8-b382-88d9c7f72a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert time into panda form to retrieve date later\n",
    "df['DDHH GMT'] = pd.to_datetime(df['DDHH GMT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e063c0ec-1e7f-4620-82e1-5c793eb50516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill negative value as missing value \n",
    "cols = df.columns[1:]\n",
    "df.iloc[:,1:][df.iloc[:,1:][cols] < 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30c7d215-b341-448c-9c91-fd74879fb718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boise_Eastman CO ppm            0\n",
      "StLukes Meridian CO ppm         0\n",
      "StLukes Meridian PM25 ugm3      0\n",
      "MBO_CO_ppbv                     0\n",
      "MBO_PM1_ug/m3                   0\n",
      "Chico_CO_ppbv                  80\n",
      "Chico_CO_MDL                   80\n",
      "Fresno_CO_ppbv                  3\n",
      "Fresno_CO_MDL                   3\n",
      "Stockton_CO                    76\n",
      "Stockton_MDL                   76\n",
      "Reno_CO                        22\n",
      "Reno_MDL                        0\n",
      "King_CO                       232\n",
      "King_MDL                        0\n",
      "Denver_CO                      39\n",
      "Denver_MDL                      0\n",
      "Ada_CO                        161\n",
      "Ada_MDL                         0\n",
      "Missoula_CO                   166\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check missing value\n",
    "print(df.iloc[:,1:].isnull().sum())\n",
    "# check value less than 0\n",
    "#print(df.iloc[:,1:][df.iloc[:,1:] < 0].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0faaf764-1862-4470-8233-f1516b166135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace data<LoD with LoD\n",
    "# Since we didn't regularize the data name and MDL, we need to deal with individual sites\n",
    "# Boise, eastman and Meridian provided by Dan are not good...\n",
    "# Mt. Bachelor, OR, okay\n",
    "flt = (df['Chico_CO_ppbv'] < df['Chico_CO_MDL'][0])&(df['Chico_CO_ppbv'] > 0)\n",
    "df['Chico_CO_ppbv'][flt] = df['Chico_CO_MDL'][0]\n",
    "\n",
    "# Chico, CA\n",
    "flt = (df['Chico_CO_ppbv'] < df['Chico_CO_MDL'][0])&(df['Chico_CO_ppbv'] > 0)\n",
    "df['Chico_CO_ppbv'][flt] = df['Chico_CO_MDL'][0]\n",
    "\n",
    "# Fresno, CA\n",
    "flt = (df['Fresno_CO_ppbv'] < df['Fresno_CO_MDL'][0])&(df['Fresno_CO_ppbv'] > 0)\n",
    "df['Fresno_CO_ppbv'][flt] = df['Fresno_CO_MDL'][0]\n",
    "\n",
    "# Stockton, CA\n",
    "flt = (df['Stockton_CO'] < df['Stockton_MDL'][0])&(df['Stockton_CO'] > 0)\n",
    "df['Stockton_CO'][flt] = df['Stockton_MDL'][0]\n",
    "\n",
    "# Reno, NV\n",
    "flt = (df['Reno_CO'] < df['Reno_MDL'][0])&(df['Reno_CO'] > 0)\n",
    "df['Reno_CO'][flt] = df['Reno_MDL'][0]\n",
    "\n",
    "# King, WA\n",
    "flt = (df['King_CO'] < df['King_MDL'][0])&(df['King_CO'] > 0)\n",
    "df['King_CO'][flt] = df['King_MDL'][0]\n",
    "\n",
    "# Denver, CO\n",
    "flt = (df['Denver_CO'] < df['Denver_MDL'][0])&(df['Denver_CO'] > 0)\n",
    "df['Denver_CO'][flt] = df['Denver_MDL'][0]\n",
    "\n",
    "# Bosie, ID\n",
    "flt = (df['Ada_CO'] < df['Ada_MDL'][0])&(df['Ada_CO'] > 0)\n",
    "df['Ada_CO'][flt] = df['Ada_MDL'][0]\n",
    "\n",
    "# Missoula, MT, okk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c9c10be-4347-4d35-9673-ab676d24080e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boise_Eastman CO ppm            0\n",
      "StLukes Meridian CO ppm         0\n",
      "StLukes Meridian PM25 ugm3      0\n",
      "MBO_CO_ppbv                     0\n",
      "MBO_PM1_ug/m3                   0\n",
      "Chico_CO_ppbv                  80\n",
      "Chico_CO_MDL                   80\n",
      "Fresno_CO_ppbv                  3\n",
      "Fresno_CO_MDL                   3\n",
      "Stockton_CO                    76\n",
      "Stockton_MDL                   76\n",
      "Reno_CO                        22\n",
      "Reno_MDL                        0\n",
      "King_CO                       232\n",
      "King_MDL                        0\n",
      "Denver_CO                      39\n",
      "Denver_MDL                      0\n",
      "Ada_CO                        161\n",
      "Ada_MDL                         0\n",
      "Missoula_CO                   166\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[:,1:].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b696100d-f044-4ca8-9441-0287e8e873f1",
   "metadata": {},
   "source": [
    "keep in mind that I am using GMT here but not local time. It's okay for WE-CAN paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c8570b8-798f-4381-9151-969ca601e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns we don't need this time\n",
    "#df_data_new  = df_data.drop(['Boise_Eastman CO ppm','StLukes Meridian CO ppm','StLukes Meridian PM25 ugm3','MBO_PM1_ug/m3'],axis=1) #the column number is fixed\n",
    "#df_data_new  = df_data.drop(['Chico_CO_MDL','Fresno_CO_MDL','Stockton_MDL','Reno_MDL','King_MDL','Denver_MDL','Ada_MDL'],axis=1) #the column number is fixed\n",
    "df_new  = df.drop(['Boise_Eastman CO ppm','StLukes Meridian CO ppm','StLukes Meridian PM25 ugm3','MBO_PM1_ug/m3',\n",
    "                             'Chico_CO_MDL','Fresno_CO_MDL','Stockton_MDL','Reno_MDL','King_MDL','Denver_MDL','Ada_MDL'],axis=1) \n",
    "\n",
    "# rename Ada as Boise\n",
    "new_names_dict = {'Ada_CO':'Boise_CO'}\n",
    "df_new.rename(columns = new_names_dict, inplace=True) #Set inplace eq 1 then the old column names will be replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "989427b8-425c-4ead-ac55-eefe63a00589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DDHH GMT</th>\n",
       "      <th>MBO_CO_ppbv</th>\n",
       "      <th>Chico_CO_ppbv</th>\n",
       "      <th>Fresno_CO_ppbv</th>\n",
       "      <th>Stockton_CO</th>\n",
       "      <th>Reno_CO</th>\n",
       "      <th>King_CO</th>\n",
       "      <th>Denver_CO</th>\n",
       "      <th>Boise_CO</th>\n",
       "      <th>Missoula_CO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018-07-22 00:00:00</td>\n",
       "      <td>103.19</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.142</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018-07-22 01:00:00</td>\n",
       "      <td>102.62</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.162</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018-07-22 02:00:00</td>\n",
       "      <td>102.87</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.177</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018-07-22 03:00:00</td>\n",
       "      <td>104.82</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.172</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018-07-22 04:00:00</td>\n",
       "      <td>103.54</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.148</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1339</td>\n",
       "      <td>2018-09-15 19:00:00</td>\n",
       "      <td>173.30</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.310</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>2018-09-15 20:00:00</td>\n",
       "      <td>168.71</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.283</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1341</td>\n",
       "      <td>2018-09-15 21:00:00</td>\n",
       "      <td>180.31</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.224</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1342</td>\n",
       "      <td>2018-09-15 22:00:00</td>\n",
       "      <td>201.65</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.243</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1343</td>\n",
       "      <td>2018-09-15 23:00:00</td>\n",
       "      <td>203.69</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.155</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1344 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                DDHH GMT  MBO_CO_ppbv  Chico_CO_ppbv  Fresno_CO_ppbv  \\\n",
       "0    2018-07-22 00:00:00       103.19          0.144           0.164   \n",
       "1    2018-07-22 01:00:00       102.62          0.152           0.155   \n",
       "2    2018-07-22 02:00:00       102.87          0.163           0.143   \n",
       "3    2018-07-22 03:00:00       104.82          0.169           0.162   \n",
       "4    2018-07-22 04:00:00       103.54          0.164           0.156   \n",
       "...                  ...          ...            ...             ...   \n",
       "1339 2018-09-15 19:00:00       173.30          0.160           0.163   \n",
       "1340 2018-09-15 20:00:00       168.71          0.160           0.161   \n",
       "1341 2018-09-15 21:00:00       180.31          0.153           0.162   \n",
       "1342 2018-09-15 22:00:00       201.65          0.129           0.162   \n",
       "1343 2018-09-15 23:00:00       203.69          0.127           0.162   \n",
       "\n",
       "      Stockton_CO  Reno_CO  King_CO  Denver_CO  Boise_CO  Missoula_CO  \n",
       "0           0.156    0.227    0.124      0.222     0.142          NaN  \n",
       "1           0.153    0.177    0.135      0.283     0.162          NaN  \n",
       "2           0.184    0.178    0.127      0.360     0.177          NaN  \n",
       "3           0.164    0.233    0.148      0.413     0.172          NaN  \n",
       "4           0.162    0.287    0.187      0.274     0.148          NaN  \n",
       "...           ...      ...      ...        ...       ...          ...  \n",
       "1339        0.148    0.082    0.162      0.169     0.310          NaN  \n",
       "1340        0.140    0.089    0.145      0.135     0.283          NaN  \n",
       "1341        0.143    0.082    0.139      0.118     0.224          NaN  \n",
       "1342        0.164    0.093    0.142      0.082     0.243          NaN  \n",
       "1343        0.161    0.090    0.157      0.080     0.155          NaN  \n",
       "\n",
       "[1344 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4dc9e5c-b2cf-4b24-be01-c93848fda696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all data in unit of ppb rather than ppm\n",
    "df_new.iloc[:,2:] = df_new.iloc[:,2:]*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "813be92a-21a5-4ca6-9898-90b817465ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rerange the columns by geophysical locations; reorder\n",
    "# WA, MBO, NV, CA, CA, CA, MT, BOISE, CO\n",
    "df_new = df_new[['DDHH GMT','King_CO','MBO_CO_ppbv','Reno_CO','Fresno_CO_ppbv','Stockton_CO','Chico_CO_ppbv','Denver_CO','Boise_CO','Missoula_CO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78a38eee-7be4-46eb-9ee5-8cf97883c4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DDHH GMT</th>\n",
       "      <th>King_CO</th>\n",
       "      <th>MBO_CO_ppbv</th>\n",
       "      <th>Reno_CO</th>\n",
       "      <th>Fresno_CO_ppbv</th>\n",
       "      <th>Stockton_CO</th>\n",
       "      <th>Chico_CO_ppbv</th>\n",
       "      <th>Denver_CO</th>\n",
       "      <th>Boise_CO</th>\n",
       "      <th>Missoula_CO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018-07-22 00:00:00</td>\n",
       "      <td>124.0</td>\n",
       "      <td>103.19</td>\n",
       "      <td>227.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018-07-22 01:00:00</td>\n",
       "      <td>135.0</td>\n",
       "      <td>102.62</td>\n",
       "      <td>177.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018-07-22 02:00:00</td>\n",
       "      <td>127.0</td>\n",
       "      <td>102.87</td>\n",
       "      <td>178.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018-07-22 03:00:00</td>\n",
       "      <td>148.0</td>\n",
       "      <td>104.82</td>\n",
       "      <td>233.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018-07-22 04:00:00</td>\n",
       "      <td>187.0</td>\n",
       "      <td>103.54</td>\n",
       "      <td>287.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2018-07-22 05:00:00</td>\n",
       "      <td>221.0</td>\n",
       "      <td>105.87</td>\n",
       "      <td>438.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2018-07-22 06:00:00</td>\n",
       "      <td>200.0</td>\n",
       "      <td>105.71</td>\n",
       "      <td>306.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2018-07-22 07:00:00</td>\n",
       "      <td>146.0</td>\n",
       "      <td>106.71</td>\n",
       "      <td>402.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2018-07-22 08:00:00</td>\n",
       "      <td>132.0</td>\n",
       "      <td>104.67</td>\n",
       "      <td>468.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2018-07-22 09:00:00</td>\n",
       "      <td>116.0</td>\n",
       "      <td>104.38</td>\n",
       "      <td>426.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DDHH GMT  King_CO  MBO_CO_ppbv  Reno_CO  Fresno_CO_ppbv  \\\n",
       "0 2018-07-22 00:00:00    124.0       103.19    227.0           164.0   \n",
       "1 2018-07-22 01:00:00    135.0       102.62    177.0           155.0   \n",
       "2 2018-07-22 02:00:00    127.0       102.87    178.0           143.0   \n",
       "3 2018-07-22 03:00:00    148.0       104.82    233.0           162.0   \n",
       "4 2018-07-22 04:00:00    187.0       103.54    287.0           156.0   \n",
       "5 2018-07-22 05:00:00    221.0       105.87    438.0           139.0   \n",
       "6 2018-07-22 06:00:00    200.0       105.71    306.0           131.0   \n",
       "7 2018-07-22 07:00:00    146.0       106.71    402.0           128.0   \n",
       "8 2018-07-22 08:00:00    132.0       104.67    468.0           127.0   \n",
       "9 2018-07-22 09:00:00    116.0       104.38    426.0           125.0   \n",
       "\n",
       "   Stockton_CO  Chico_CO_ppbv  Denver_CO  Boise_CO  Missoula_CO  \n",
       "0        156.0          144.0      222.0     142.0          NaN  \n",
       "1        153.0          152.0      283.0     162.0          NaN  \n",
       "2        184.0          163.0      360.0     177.0          NaN  \n",
       "3        164.0          169.0      413.0     172.0          NaN  \n",
       "4        162.0          164.0      274.0     148.0          NaN  \n",
       "5        171.0          144.0      216.0     149.0          NaN  \n",
       "6        149.0          135.0      279.0     129.0          NaN  \n",
       "7        135.0          148.0      337.0     115.0          NaN  \n",
       "8        118.0          137.0      257.0     121.0          NaN  \n",
       "9        103.0          124.0      246.0     106.0          NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45c3baa6-155a-43b3-be8a-4acd556955ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DDHH GMT</th>\n",
       "      <th>Seattle, WA</th>\n",
       "      <th>Mt. Bachelor, OR</th>\n",
       "      <th>Reno, NV</th>\n",
       "      <th>Fresno, CA</th>\n",
       "      <th>Stockton, CA</th>\n",
       "      <th>Chico, CA</th>\n",
       "      <th>Denver, CO</th>\n",
       "      <th>Boise, ID</th>\n",
       "      <th>Missoula, MT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018-07-22 00:00:00</td>\n",
       "      <td>124.0</td>\n",
       "      <td>103.19</td>\n",
       "      <td>227.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018-07-22 01:00:00</td>\n",
       "      <td>135.0</td>\n",
       "      <td>102.62</td>\n",
       "      <td>177.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018-07-22 02:00:00</td>\n",
       "      <td>127.0</td>\n",
       "      <td>102.87</td>\n",
       "      <td>178.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018-07-22 03:00:00</td>\n",
       "      <td>148.0</td>\n",
       "      <td>104.82</td>\n",
       "      <td>233.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018-07-22 04:00:00</td>\n",
       "      <td>187.0</td>\n",
       "      <td>103.54</td>\n",
       "      <td>287.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2018-07-22 05:00:00</td>\n",
       "      <td>221.0</td>\n",
       "      <td>105.87</td>\n",
       "      <td>438.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2018-07-22 06:00:00</td>\n",
       "      <td>200.0</td>\n",
       "      <td>105.71</td>\n",
       "      <td>306.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2018-07-22 07:00:00</td>\n",
       "      <td>146.0</td>\n",
       "      <td>106.71</td>\n",
       "      <td>402.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2018-07-22 08:00:00</td>\n",
       "      <td>132.0</td>\n",
       "      <td>104.67</td>\n",
       "      <td>468.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2018-07-22 09:00:00</td>\n",
       "      <td>116.0</td>\n",
       "      <td>104.38</td>\n",
       "      <td>426.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DDHH GMT  Seattle, WA  Mt. Bachelor, OR  Reno, NV  Fresno, CA  \\\n",
       "0 2018-07-22 00:00:00        124.0            103.19     227.0       164.0   \n",
       "1 2018-07-22 01:00:00        135.0            102.62     177.0       155.0   \n",
       "2 2018-07-22 02:00:00        127.0            102.87     178.0       143.0   \n",
       "3 2018-07-22 03:00:00        148.0            104.82     233.0       162.0   \n",
       "4 2018-07-22 04:00:00        187.0            103.54     287.0       156.0   \n",
       "5 2018-07-22 05:00:00        221.0            105.87     438.0       139.0   \n",
       "6 2018-07-22 06:00:00        200.0            105.71     306.0       131.0   \n",
       "7 2018-07-22 07:00:00        146.0            106.71     402.0       128.0   \n",
       "8 2018-07-22 08:00:00        132.0            104.67     468.0       127.0   \n",
       "9 2018-07-22 09:00:00        116.0            104.38     426.0       125.0   \n",
       "\n",
       "   Stockton, CA  Chico, CA  Denver, CO  Boise, ID  Missoula, MT  \n",
       "0         156.0      144.0       222.0      142.0           NaN  \n",
       "1         153.0      152.0       283.0      162.0           NaN  \n",
       "2         184.0      163.0       360.0      177.0           NaN  \n",
       "3         164.0      169.0       413.0      172.0           NaN  \n",
       "4         162.0      164.0       274.0      148.0           NaN  \n",
       "5         171.0      144.0       216.0      149.0           NaN  \n",
       "6         149.0      135.0       279.0      129.0           NaN  \n",
       "7         135.0      148.0       337.0      115.0           NaN  \n",
       "8         118.0      137.0       257.0      121.0           NaN  \n",
       "9         103.0      124.0       246.0      106.0           NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename columns\n",
    "new_names_dict = {'King_CO':'Seattle, WA', \n",
    "                  'MBO_CO_ppbv': 'Mt. Bachelor, OR', \n",
    "                  'Reno_CO': 'Reno, NV', \n",
    "                  'Fresno_CO_ppbv': 'Fresno, CA',\n",
    "                  'Stockton_CO': 'Stockton, CA',\n",
    "                  'Chico_CO_ppbv':'Chico, CA',\n",
    "                  'Denver_CO': 'Denver, CO',\n",
    "                  'Boise_CO': 'Boise, ID',\n",
    "                  'Missoula_CO': 'Missoula, MT'}\n",
    "df_obs = df_new.rename(columns = new_names_dict, inplace=False) #Set inplace eq 1 then the old column names will be replaced\n",
    "df_obs.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b766ddc-3441-4a3e-8930-0d949e7afac2",
   "metadata": {},
   "source": [
    "So far, we have prepared the data. Time range could be customed if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40e8c009-9edf-4c42-b9a6-780970915788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create daily data\n",
    "# resampble data, average data into daily\n",
    "df_obs_daily = df_obs.resample('D', on='DDHH GMT').mean()\n",
    "\n",
    "# create diurnal data\n",
    "# create a tmp variable to avoid messing up with df_new\n",
    "tmp = df_obs\n",
    "# add a column to show hour of the day\n",
    "tmp['HH'] = tmp['DDHH GMT'].map(lambda x: x.strftime(\"%H:%M\"))\n",
    "# group by the hour to get dirunal pattern\n",
    "df_obs_diurnal = tmp.groupby('HH').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc264c6-c394-4945-a9c8-39f1f1119b35",
   "metadata": {},
   "source": [
    "### Read model data in netcdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "380dcc22-43c8-4d64-9cc7-d276b7309d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xarray allows us to read in any NetCDF file, the format of most GEOS-Chem diagnostics, as an xarray Dataset\n",
    "import xarray as xr\n",
    "import datetime\n",
    "from dateutil.rrule import rrule, DAILY\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fccc84-c407-456a-b4c5-ae4ce7cff512",
   "metadata": {},
   "source": [
    "#### Define a function to read in sites data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d20543-9650-4a3b-9058-82ac83cbf8eb",
   "metadata": {},
   "source": [
    "##### Read in model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce3c34f1-7ca5-4b60-98cf-32a0ff309d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_site_data_V13(files_pfx,start_date,end_date):\n",
    "    fl_sfx = '_0000z.nc4'\n",
    "    site = files_pfx.split('_')[1].split('.')[0]\n",
    "    \n",
    "    # use a normal list to save data later\n",
    "    co_mod_list = []\n",
    "    date_mod_list = []\n",
    "    \n",
    "    for day in rrule(DAILY, dtstart=start_date, until=end_date):\n",
    "        day_fmt = datetime.datetime.strftime(day, '%Y%m%d')\n",
    "        src_fl = '{0}{1}{2}'.format(files_pfx, day_fmt, fl_sfx)\n",
    "        \n",
    "        print(src_fl)\n",
    "        \n",
    "        ds = xr.open_dataset(src_fl)\n",
    "        tmp = ds['SpeciesConc_CO'][:,0,0,0].values.tolist()\n",
    "        # create data\n",
    "        co_mod_list.append(tmp)\n",
    "        # craete date\n",
    "        date_mod_list.append(day_fmt)\n",
    "        #sys.exit()\n",
    "        \n",
    "    # output the shape of the list\n",
    "    np.shape(co_mod_list)\n",
    "\n",
    "    # convert the data list into dataframe\n",
    "    # convert mol/mol to ppb\n",
    "    co_mod_df = pd.DataFrame(co_mod_list, index = date_mod_list)*1e9\n",
    "    co_mod_df.head(10)\n",
    "\n",
    "    # create diurnal pattern\n",
    "    co_mod_daily = pd.DataFrame(co_mod_df.mean(axis=1),columns=[site])\n",
    "    \n",
    "    # return the diurnal pattern\n",
    "    return co_mod_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "584d0c2c-d3c6-4885-9bba-7285120eca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "def get_site_data_V12(file_dir, start_date, end_date, MBO, compound):\n",
    "    # create date lists\n",
    "    date_list = []\n",
    "    for day in rrule(DAILY, dtstart=start_date, until=end_date):\n",
    "        date_list = date_list + [datetime.datetime.strftime(day, '%Y-%m-%d')]\n",
    "\n",
    "    if MBO == True:\n",
    "        station_num = 10\n",
    "        data_tmp = []\n",
    "        for day in rrule(DAILY, dtstart=start_date, until=end_date):\n",
    "            day_fmt = datetime.datetime.strftime(day, '%Y%m%d')\n",
    "            src_fl = '{0}{1}{2}'.format(file_dir+'stations.', day_fmt, '.nc')\n",
    "            if exists(src_fl):\n",
    "                ds = xr.open_dataset(src_fl)\n",
    "                tmp = ds['IJ_AVG_S_' + compound][:,0,0].values.tolist()\n",
    "                data_tmp = data_tmp + tmp\n",
    "            \n",
    "            \n",
    "        data_tmp = np.array(data_tmp).reshape(int(len(data_tmp)/station_num), station_num)\n",
    "        #Seattle, King-North Beacon Hill\n",
    "        data_mod_king = data_tmp[:,0]\n",
    "        data_mod_king =data_mod_king.reshape(int(len(data_mod_king)/24), 24).mean(1)\n",
    "\n",
    "        #Portland, Multnomah, no good\n",
    "        data_mod_portland = data_tmp[:,1]\n",
    "        data_mod_portland =data_mod_portland.reshape(int(len(data_mod_portland)/24), 24).mean(1)\n",
    "\n",
    "        #Boise, Ada-Meridian\n",
    "        data_mod_ada = data_tmp[:,2]\n",
    "        data_mod_ada =data_mod_ada.reshape(int(len(data_mod_ada)/24), 24).mean(1)\n",
    "\n",
    "        #Denver, Denver-sunnyside\n",
    "        data_mod_denver = data_tmp[:,3]\n",
    "        data_mod_denver =data_mod_denver.reshape(int(len(data_mod_denver)/24), 24).mean(1)\n",
    "        \n",
    "        #Stockton, San Joaquin\n",
    "        data_mod_sanjoquin = data_tmp[:,4]\n",
    "        data_mod_sanjoquin =data_mod_sanjoquin.reshape(int(len(data_mod_sanjoquin)/24), 24).mean(1)\n",
    "        \n",
    "        #Fresno, Fresno-3727 N first str\n",
    "        data_mod_fresno = data_tmp[:,5]\n",
    "        data_mod_fresno =data_mod_fresno.reshape(int(len(data_mod_fresno)/24), 24).mean(1)\n",
    "\n",
    "        #Reno, Washoe-98-02 river rock st.\n",
    "        data_mod_washoe = data_tmp[:,7]\n",
    "        data_mod_washoe =data_mod_washoe.reshape(int(len(data_mod_washoe)/24), 24).mean(1)\n",
    "        #Chico, Butte\n",
    "        data_mod_butte = data_tmp[:,8]\n",
    "        data_mod_butte =data_mod_butte.reshape(int(len(data_mod_butte)/24), 24).mean(1)\n",
    "        #Missoula, missoula-UM\n",
    "        data_mod_missoula = data_tmp[:,9]\n",
    "        data_mod_missoula =data_mod_missoula.reshape(int(len(data_mod_missoula)/24), 24).mean(1)\n",
    "        \n",
    "        data = {'Seattle, WA': data_mod_king,\n",
    "                'Boise, ID': data_mod_ada,\n",
    "                'Denver, CO': data_mod_denver,\n",
    "                'Stockton, CA':  data_mod_sanjoquin,\n",
    "                'Fresno, CA': data_mod_fresno,\n",
    "                'Reno, NV': data_mod_washoe,\n",
    "                'Chico, CA': data_mod_butte,\n",
    "                'Missoula, MT': data_mod_missoula}\n",
    "    else:\n",
    "        data_mod_MBO = []\n",
    "        # create normal list\n",
    "        for day in rrule(DAILY, dtstart=start_date, until=end_date):\n",
    "            day_fmt = datetime.datetime.strftime(day, '%Y%m%d')\n",
    "            src_fl = '{0}{1}{2}'.format(file_dir+'ts', day_fmt, '.nc')\n",
    "            ds = xr.open_dataset(src_fl)\n",
    "            tmp = ds['IJ_AVG_S_' + compound][:,0,0,16].values.tolist()\n",
    "            data_mod_MBO = data_mod_MBO + tmp\n",
    "\n",
    "        data_mod_MBO=np.array(data_mod_MBO)\n",
    "        #MBO\n",
    "        data_mod_MBO =data_mod_MBO.reshape(int(len(data_mod_MBO)/24), 24).mean(1)\n",
    "        \n",
    "        data = {'Mt. Bachelor, OR':data_mod_MBO}\n",
    "        \n",
    "    df_mod_sites = pd.DataFrame(data, index = date_list)\n",
    "    return df_mod_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cf5feb2-11ca-4c9f-b218-6102fa35ac52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# function to print out correlations for numpy data (obsolete)\\ndef correlation(A, B):\\n    return np.ma.corrcoef(A,B)[0][1]\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# function to print out correlations for numpy data (obsolete)\n",
    "def correlation(A, B):\n",
    "    return np.ma.corrcoef(A,B)[0][1]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28fe0f82-8aba-4b10-9a2f-468ea63c959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CO\n",
    "file_dir_gfas = '/glade/scratch/lixujin/rundirs/GC12.5.0/geosfp_025x03125_tropchem_na_gfas_sf_mami/stations/'\n",
    "file_dir_threegfas = '/glade/scratch/lixujin/rundirs/GC12.5.0/geosfp_025x03125_tropchem_na_3Xgfas_sf_mami/stations/'\n",
    "file_dir_nobb = '/glade/scratch/lixujin/rundirs/GC12.5.0/geosfp_025x03125_tropchem_na_nobb_v2/stations/'\n",
    "\n",
    "start_date = datetime.date(2018,7,22)\n",
    "end_date = datetime.date(2018,9,14)\n",
    "\n",
    "df_mod_CO_base = pd.concat([get_site_data_V12(file_dir_gfas, start_date, end_date, MBO=True, compound='CO'),\n",
    "                            get_site_data_V12(file_dir_gfas, start_date, end_date, MBO=False, compound='CO')],  axis=1)\n",
    "\n",
    "df_mod_CO_threegfas = pd.concat([get_site_data_V12(file_dir_threegfas, start_date, end_date, MBO=True, compound='CO'),\n",
    "                                 get_site_data_V12(file_dir_threegfas, start_date, end_date, MBO=False, compound='CO')],  axis=1)\n",
    "\n",
    "df_mod_CO_nobb = pd.concat([get_site_data_V12(file_dir_nobb, start_date, end_date, MBO=True, compound='CO'),\n",
    "                                 get_site_data_V12(file_dir_nobb, start_date, end_date, MBO=False, compound='CO')],  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a624602-8a57-4555-9772-9741264aeb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# PM2.5\\ndef PM_calcualtion(file_dir, start_date, end_date):\\n    df_mod_NH4 = pd.concat([get_site_data_V12(file_dir, start_date, end_date, MBO=True, compound='NH4'),\\n                            get_site_data_V12(file_dir, start_date, end_date, MBO=False, compound='NH4')],  axis=1)\\n    df_mod_NIT = pd.concat([get_site_data_V12(file_dir, start_date, end_date, MBO=True, compound='NIT'),\\n                            get_site_data_V12(file_dir, start_date, end_date, MBO=False, compound='NIT')],  axis=1)\\n    df_mod_SO4 = pd.concat([get_site_data_V12(file_dir, start_date, end_date, MBO=True, compound='SO4'),\\n                            get_site_data_V12(file_dir, start_date, end_date, MBO=False, compound='SO4')],  axis=1)\\n    df_mod_BCPI = pd.concat([get_site_data_V12(file_dir, start_date, end_date, MBO=True, compound='BCPI'),\\n                            get_site_data_V12(file_dir, start_date, end_date, MBO=False, compound='BCPI')],  axis=1)\\n    df_mod_BCPO = pd.concat([get_site_data_V12(file_dir, start_date, end_date, MBO=True, compound='BCPO'),\\n                            get_site_data_V12(file_dir, start_date, end_date, MBO=False, compound='BCPO')],  axis=1)\\n    df_mod_OCPI = pd.concat([get_site_data_V12(file_dir, start_date, end_date, MBO=True, compound='OCPI'),\\n                            get_site_data_V12(file_dir, start_date, end_date, MBO=False, compound='OCPI')],  axis=1)\\n    df_mod_OCPO = pd.concat([get_site_data_V12(file_dir, start_date, end_date, MBO=True, compound='OCPO'),\\n                            get_site_data_V12(file_dir, start_date, end_date, MBO=False, compound='OCPO')],  axis=1)\\n    df_mod_SOAS = pd.concat([get_site_data_V12(file_dir, start_date, end_date, MBO=True, compound='SOAS'),\\n                            get_site_data_V12(file_dir, start_date, end_date, MBO=False, compound='SOAS')],  axis=1)\\n    df_mod_DST1 = pd.concat([get_site_data_V12(file_dir, start_date, end_date, MBO=True, compound='DST1'),\\n                            get_site_data_V12(file_dir, start_date, end_date, MBO=False, compound='DST1')],  axis=1)\\n    df_mod_DST2 = pd.concat([get_site_data_V12(file_dir, start_date, end_date, MBO=True, compound='DST2'),\\n                            get_site_data_V12(file_dir, start_date, end_date, MBO=False, compound='DST2')],  axis=1)\\n    df_mod_SALA = pd.concat([get_site_data_V12(file_dir, start_date, end_date, MBO=True, compound='SALA'),\\n                            get_site_data_V12(file_dir, start_date, end_date, MBO=False, compound='SALA')],  axis=1)\\n\\n    df_mod_pm_1 = df_mod_NH4.add(df_mod_NIT).add(df_mod_SO4).mul(1.33)\\n    df_mod_pm_2 = df_mod_BCPI.add(df_mod_BCPO)\\n    df_mod_pm_3 = df_mod_OCPI.mul(1.16).add(df_mod_OCPO).mul(2.1)\\n    df_mod_pm_4 = df_mod_SOAS.mul(1.16).add(df_mod_DST1)\\n    df_mod_pm_5 = df_mod_DST2.mul(0.38)\\n    df_mod_pm_6 = df_mod_SALA.mul(1.86)\\n    \\n    df_mod_pm = df_mod_pm_1.add(df_mod_pm_2).add(df_mod_pm_3).add(df_mod_pm_4).add(df_mod_pm_5).add(df_mod_pm_6)\\n    \\n    return df_mod_pm\\ndf_mod_PM = PM_calcualtion(file_dir, start_date, end_date)\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# PM2.5\n",
    "def PM_calcualtion(file_dir, start_date, end_date):\n",
    "    df_mod_NH4 = pd.concat([get_site_data_V12(file_dir, start_date, end_date, MBO=True, compound='NH4'),\n",
    "                            get_site_data_V12(file_dir, start_date, end_date, MBO=False, compound='NH4')],  axis=1)\n",
    "    df_mod_NIT = pd.concat([get_site_data_V12(file_dir, start_date, end_date, MBO=True, compound='NIT'),\n",
    "                            get_site_data_V12(file_dir, start_date, end_date, MBO=False, compound='NIT')],  axis=1)\n",
    "    df_mod_SO4 = pd.concat([get_site_data_V12(file_dir, start_date, end_date, MBO=True, compound='SO4'),\n",
    "                            get_site_data_V12(file_dir, start_date, end_date, MBO=False, compound='SO4')],  axis=1)\n",
    "    df_mod_BCPI = pd.concat([get_site_data_V12(file_dir, start_date, end_date, MBO=True, compound='BCPI'),\n",
    "                            get_site_data_V12(file_dir, start_date, end_date, MBO=False, compound='BCPI')],  axis=1)\n",
    "    df_mod_BCPO = pd.concat([get_site_data_V12(file_dir, start_date, end_date, MBO=True, compound='BCPO'),\n",
    "                            get_site_data_V12(file_dir, start_date, end_date, MBO=False, compound='BCPO')],  axis=1)\n",
    "    df_mod_OCPI = pd.concat([get_site_data_V12(file_dir, start_date, end_date, MBO=True, compound='OCPI'),\n",
    "                            get_site_data_V12(file_dir, start_date, end_date, MBO=False, compound='OCPI')],  axis=1)\n",
    "    df_mod_OCPO = pd.concat([get_site_data_V12(file_dir, start_date, end_date, MBO=True, compound='OCPO'),\n",
    "                            get_site_data_V12(file_dir, start_date, end_date, MBO=False, compound='OCPO')],  axis=1)\n",
    "    df_mod_SOAS = pd.concat([get_site_data_V12(file_dir, start_date, end_date, MBO=True, compound='SOAS'),\n",
    "                            get_site_data_V12(file_dir, start_date, end_date, MBO=False, compound='SOAS')],  axis=1)\n",
    "    df_mod_DST1 = pd.concat([get_site_data_V12(file_dir, start_date, end_date, MBO=True, compound='DST1'),\n",
    "                            get_site_data_V12(file_dir, start_date, end_date, MBO=False, compound='DST1')],  axis=1)\n",
    "    df_mod_DST2 = pd.concat([get_site_data_V12(file_dir, start_date, end_date, MBO=True, compound='DST2'),\n",
    "                            get_site_data_V12(file_dir, start_date, end_date, MBO=False, compound='DST2')],  axis=1)\n",
    "    df_mod_SALA = pd.concat([get_site_data_V12(file_dir, start_date, end_date, MBO=True, compound='SALA'),\n",
    "                            get_site_data_V12(file_dir, start_date, end_date, MBO=False, compound='SALA')],  axis=1)\n",
    "\n",
    "    df_mod_pm_1 = df_mod_NH4.add(df_mod_NIT).add(df_mod_SO4).mul(1.33)\n",
    "    df_mod_pm_2 = df_mod_BCPI.add(df_mod_BCPO)\n",
    "    df_mod_pm_3 = df_mod_OCPI.mul(1.16).add(df_mod_OCPO).mul(2.1)\n",
    "    df_mod_pm_4 = df_mod_SOAS.mul(1.16).add(df_mod_DST1)\n",
    "    df_mod_pm_5 = df_mod_DST2.mul(0.38)\n",
    "    df_mod_pm_6 = df_mod_SALA.mul(1.86)\n",
    "    \n",
    "    df_mod_pm = df_mod_pm_1.add(df_mod_pm_2).add(df_mod_pm_3).add(df_mod_pm_4).add(df_mod_pm_5).add(df_mod_pm_6)\n",
    "    \n",
    "    return df_mod_pm\n",
    "df_mod_PM = PM_calcualtion(file_dir, start_date, end_date)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad3468ff-76ec-45c9-8f6b-1a4f825df350",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obs_daily = df_obs_daily.reindex(['Seattle, WA','Boise, ID','Missoula, MT', \n",
    "                                    'Mt. Bachelor, OR', 'Reno, NV', 'Denver, CO',\n",
    "                                    'Chico, CA', 'Stockton, CA', 'Fresno, CA'], axis=1)[:-1]\n",
    "df_mod_CO_base = df_mod_CO_base.reindex(['Seattle, WA','Boise, ID','Missoula, MT', \n",
    "                                    'Mt. Bachelor, OR', 'Reno, NV', 'Denver, CO',\n",
    "                                    'Chico, CA', 'Stockton, CA', 'Fresno, CA'], axis=1)\n",
    "df_mod_CO_threegfas = df_mod_CO_threegfas.reindex(['Seattle, WA','Boise, ID','Missoula, MT', \n",
    "                                    'Mt. Bachelor, OR', 'Reno, NV', 'Denver, CO',\n",
    "                                    'Chico, CA', 'Stockton, CA', 'Fresno, CA'], axis=1)\n",
    "df_mod_CO_nobb = df_mod_CO_nobb.reindex(['Seattle, WA','Boise, ID','Missoula, MT', \n",
    "                                    'Mt. Bachelor, OR', 'Reno, NV', 'Denver, CO',\n",
    "                                    'Chico, CA', 'Stockton, CA', 'Fresno, CA'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7d8a6fb-e7eb-4990-b736-ab5f42983d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2018-07-22', '2018-07-23', '2018-07-24', '2018-07-25',\n",
       "               '2018-07-26', '2018-07-27', '2018-07-28', '2018-07-29',\n",
       "               '2018-07-30', '2018-07-31', '2018-08-01', '2018-08-02',\n",
       "               '2018-08-03', '2018-08-04', '2018-08-05', '2018-08-06',\n",
       "               '2018-08-07', '2018-08-08', '2018-08-09', '2018-08-10',\n",
       "               '2018-08-11', '2018-08-12', '2018-08-13', '2018-08-14',\n",
       "               '2018-08-15', '2018-08-16', '2018-08-17', '2018-08-18',\n",
       "               '2018-08-19', '2018-08-20', '2018-08-21', '2018-08-22',\n",
       "               '2018-08-23', '2018-08-24', '2018-08-25', '2018-08-26',\n",
       "               '2018-08-27', '2018-08-28', '2018-08-29', '2018-08-30',\n",
       "               '2018-08-31', '2018-09-01', '2018-09-02', '2018-09-03',\n",
       "               '2018-09-04', '2018-09-05', '2018-09-06', '2018-09-07',\n",
       "               '2018-09-08', '2018-09-09', '2018-09-10', '2018-09-11',\n",
       "               '2018-09-12', '2018-09-13', '2018-09-14'],\n",
       "              dtype='datetime64[ns]', name='DDHH GMT', freq='D')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_obs_daily.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3dbe3941-b3d0-4426-858b-358626b0bead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.362391153971345\n",
      "20.094971021016434\n",
      "2.906787122660319\n",
      "8.224775911966958\n",
      "9.583048502604171\n",
      "1.0756969451904297\n",
      "37.58309853595236\n",
      "18.88151417607847\n",
      "29.75326633453369\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.font_manager as font_manager\n",
    "import math\n",
    "# ============\n",
    "# Plot setting\n",
    "# ============\n",
    "linewidth = 3\n",
    "\n",
    "\n",
    "# =================================\n",
    "# initialzie data for later saveout\n",
    "# =================================\n",
    "# site\n",
    "site_names = []\n",
    "# =====================\n",
    "# statistical variables\n",
    "# =====================\n",
    "# entire season\n",
    "MB_base_entire = []\n",
    "RMSE_base_entire = []\n",
    "R_base_entire = []\n",
    "MB_threegfas_entire = []\n",
    "RMSE_threegfas_entire = []\n",
    "R_threegfas_entire = []\n",
    "# BB-impacted\n",
    "MB_base_smoky = []\n",
    "RMSE_base_smoky = []\n",
    "R_base_smoky = []\n",
    "MB_threegfas_smoky = []\n",
    "RMSE_threegfas_smoky = []\n",
    "R_threegfas_smoky = []\n",
    "# least BB-impacted\n",
    "MB_base_nonsmoky = []\n",
    "RMSE_base_nonsmoky = []\n",
    "R_base_nonsmoky = []\n",
    "MB_threegfas_nonsmoky = []\n",
    "RMSE_threegfas_nonsmoky = []\n",
    "R_threegfas_nonsmoky = []\n",
    "\n",
    "# walk through each site\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18,15),sharex=True)\n",
    "for cols, ax in zip(df_obs_daily.columns[0:], axes.flatten()):\n",
    "    site_names.append(cols)\n",
    "    # ============\n",
    "    # data process\n",
    "    # ============\n",
    "    # Making model values as False if observations are.\n",
    "    # creating bool series False for NaN values \n",
    "    bool_series = pd.notnull(df_obs_daily[cols])\n",
    "    df_mod_CO_base[cols] = df_mod_CO_base[cols][bool_series]\n",
    "    df_mod_CO_threegfas[cols] = df_mod_CO_threegfas[cols][bool_series]\n",
    "    df_mod_CO_nobb[cols] = df_mod_CO_nobb[cols][bool_series]\n",
    "    \n",
    "    # Define BB-impacted days as when the modeled CO daily enhancement is increased by more than 20% \n",
    "    # creating bool series for smoky and non-smoky days\n",
    "    bool_series_smoky = (df_mod_CO_base[cols]-df_mod_CO_nobb[cols])/df_mod_CO_nobb[cols] >= 0.2\n",
    "    bool_series_nonsmoky = (df_mod_CO_base[cols]-df_mod_CO_nobb[cols])/df_mod_CO_nobb[cols] < 0.2\n",
    "\n",
    "    df_obs_daily_smoky = df_obs_daily[cols][bool_series_smoky]\n",
    "    df_obs_daily_nonsmoky = df_obs_daily[cols][bool_series_nonsmoky]\n",
    "    df_mod_CO_base_smoky = df_mod_CO_base[cols][bool_series_smoky]\n",
    "    df_mod_CO_base_nonsmoky = df_mod_CO_base[cols][bool_series_nonsmoky]\n",
    "    df_mod_CO_threegfas_smoky = df_mod_CO_threegfas[cols][bool_series_smoky]\n",
    "    df_mod_CO_threegfas_nonsmoky = df_mod_CO_threegfas[cols][bool_series_nonsmoky]\n",
    "    \n",
    "    # Develop data for specific time period (obsolete)\n",
    "    # specific time, i.e., july 24th to August 11th\n",
    "    start_date = datetime.date(2018,7,25)\n",
    "    end_date = datetime.date(2018,8,11)\n",
    "    date_custom = []\n",
    "    for day in rrule(DAILY, dtstart=start_date, until=end_date):\n",
    "        day_fmt = datetime.datetime.strftime(day, '%Y-%m-%d')\n",
    "        date_custom = date_custom + [day_fmt]\n",
    "        date_custom_obs = pd.to_datetime(date_custom)\n",
    "    df_obs_daily_spec = df_obs_daily[cols][date_custom_obs]\n",
    "    df_mod_CO_base_spec = df_mod_CO_base[cols][date_custom]\n",
    "    df_mod_CO_threegfas_spec = df_mod_CO_threegfas[cols][date_custom]\n",
    "    \n",
    "    # Select data points when negative bias of CO > 100 ppb for smoky days.\n",
    "    bool_series_smoky_100bias = (df_obs_daily_smoky-df_mod_CO_base_smoky)>100\n",
    "    df_obs_daily_smoky_100bias = df_obs_daily_smoky[bool_series_smoky_100bias] \n",
    "    df_mod_CO_base_smoky_100bias = df_mod_CO_base_smoky[bool_series_smoky_100bias]\n",
    "    df_mod_CO_threegfas_smoky_100bias = df_mod_CO_threegfas_smoky[bool_series_smoky_100bias]\n",
    "\n",
    "    # =====================\n",
    "    # statistical analysis\n",
    "    # =====================\n",
    "    # for the entire season\n",
    "    # print(\"This is for entire campaign.\")\n",
    "    data_obs_daily = df_obs_daily[cols].dropna()\n",
    "    data_mod_CO_base = df_mod_CO_base[cols].dropna()\n",
    "    data_mod_CO_threegfas = df_mod_CO_threegfas[cols].dropna()\n",
    "    \n",
    "    MB_base_entire.append(-np.mean(data_obs_daily-data_mod_CO_base))\n",
    "    RMSE_base_entire.append(math.sqrt(mean_squared_error(data_obs_daily, data_mod_CO_base)))\n",
    "    R_base_entire.append(np.ma.corrcoef(data_obs_daily, data_mod_CO_base)[0,1])\n",
    "    \n",
    "    MB_threegfas_entire.append(-np.mean(data_obs_daily-data_mod_CO_threegfas))\n",
    "    RMSE_threegfas_entire.append(math.sqrt(mean_squared_error(data_obs_daily, data_mod_CO_threegfas)))\n",
    "    R_threegfas_entire.append(np.ma.corrcoef(data_obs_daily, data_mod_CO_threegfas)[0,1])\n",
    "\n",
    "    # for the smoky data\n",
    "    # print(\"This is for smoky data.\")\n",
    "    data_obs_daily_smoky = df_obs_daily_smoky.dropna()\n",
    "    data_mod_CO_base_smoky = df_mod_CO_base_smoky.dropna()\n",
    "    data_mod_CO_threegfas_smoky = df_mod_CO_threegfas_smoky.dropna()\n",
    "    \n",
    "    MB_base_smoky.append(-np.mean(data_obs_daily_smoky-data_mod_CO_base_smoky))\n",
    "    RMSE_base_smoky.append(math.sqrt(mean_squared_error(data_obs_daily_smoky, data_mod_CO_base_smoky)))\n",
    "    R_base_smoky.append(np.ma.corrcoef(data_obs_daily_smoky, data_mod_CO_base_smoky)[0,1])\n",
    "    \n",
    "    MB_threegfas_smoky.append(-np.mean(data_obs_daily_smoky-data_mod_CO_threegfas_smoky))\n",
    "    RMSE_threegfas_smoky.append(math.sqrt(mean_squared_error(data_obs_daily_smoky, data_mod_CO_threegfas_smoky)))\n",
    "    R_threegfas_smoky.append(np.ma.corrcoef(data_obs_daily_smoky, data_mod_CO_threegfas_smoky)[0,1])\n",
    "\n",
    "    # for the nonsmoky data\n",
    "    # print(\"This is for nonsmoky data.\")\n",
    "    data_obs_daily_nonsmoky = df_obs_daily_nonsmoky.dropna()\n",
    "    data_mod_CO_base_nonsmoky = df_mod_CO_base_nonsmoky.dropna()\n",
    "    data_mod_CO_threegfas_nonsmoky = df_mod_CO_threegfas_nonsmoky.dropna()\n",
    "    \n",
    "    MB_base_nonsmoky.append(-np.mean(data_obs_daily_nonsmoky-data_mod_CO_base_nonsmoky))\n",
    "    RMSE_base_nonsmoky.append(math.sqrt(mean_squared_error(data_obs_daily_nonsmoky, data_mod_CO_base_nonsmoky)))\n",
    "    R_base_nonsmoky.append(np.ma.corrcoef(data_obs_daily_nonsmoky, data_mod_CO_base_nonsmoky)[0,1])\n",
    "    \n",
    "    MB_threegfas_nonsmoky.append(-np.mean(data_obs_daily_nonsmoky-data_mod_CO_threegfas_nonsmoky))\n",
    "    RMSE_threegfas_nonsmoky.append(math.sqrt(mean_squared_error(data_obs_daily_nonsmoky, data_mod_CO_threegfas_nonsmoky)))\n",
    "    R_threegfas_nonsmoky.append(np.ma.corrcoef(data_obs_daily_nonsmoky, data_mod_CO_threegfas_nonsmoky)[0,1])\n",
    "\n",
    "    # test for bkg values (defined the bkg as the lowest 5th of the non smoky days\n",
    "    print(np.min(abs(-data_obs_daily_nonsmoky+data_mod_CO_base_nonsmoky)))\n",
    "    \n",
    "    '''\n",
    "    # specific dates\n",
    "    print('customized days')\n",
    "    if cols == 'Fresno, CA':\n",
    "        # correlation\n",
    "        print(np.corrcoef(df_obs_daily_spec, df_mod_CO_base_spec)[0,1],\n",
    "              np.corrcoef(df_obs_daily_spec, df_mod_CO_threegfas_spec)[0,1])\n",
    "        # mean bias\n",
    "        print(np.mean(df_obs_daily_spec-df_mod_CO_base_spec), \n",
    "              np.mean(df_obs_daily_spec-df_mod_CO_threegfas_spec))\n",
    "\n",
    "        # Root Mean Square Error\n",
    "        MSE_base  = mean_squared_error(df_obs_daily_spec, df_mod_CO_base_spec)\n",
    "        RMSE_base = math.sqrt(MSE_base)\n",
    "        MSE_threegfas  = mean_squared_error(df_obs_daily_spec, df_mod_CO_threegfas_spec)\n",
    "        RMSE_threegfas = math.sqrt(MSE_threegfas)\n",
    "        print(RMSE_base,\n",
    "              RMSE_threegfas)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # ===============\n",
    "    # plot the figure\n",
    "    # ===============\n",
    "    ax.plot(df_obs_daily.index, df_obs_daily[cols], \n",
    "            color='black',  label='Observation', linewidth=linewidth)\n",
    "    ax.plot(df_obs_daily.index, df_mod_CO_base[cols], \n",
    "            color = 'blue', label='GEOS-Chem + GFAS', linewidth=linewidth)\n",
    "    ax.plot(df_obs_daily.index, df_mod_CO_threegfas[cols], \n",
    "            ':', color = 'grey', label='GEOS-Chem + 3×GFAS', linewidth=linewidth)\n",
    "    ax.plot(df_obs_daily.index, df_mod_CO_nobb[cols],\n",
    "            ':', color='hotpink', label='GEOS-Chem + noBB', linewidth=linewidth)\n",
    "    \n",
    "    if cols == 'Missoula, MT':\n",
    "        font = font_manager.FontProperties(size=10,\n",
    "                                           weight='semibold')\n",
    "        ax.legend(loc=\"upper right\", prop=font)\n",
    "    \n",
    "    # fill out the smoky days\n",
    "    ax.fill_between(df_obs_daily.index, 0, 1, where=bool_series_smoky, alpha=0.2, transform=ax.get_xaxis_transform())\n",
    "\n",
    "    # Spacing Out\n",
    "    plt.subplots_adjust(wspace=.10, hspace=.10)\n",
    "    ax.set_title(cols, fontsize=15) \n",
    "    \n",
    "    # xrange and yrange\n",
    "    if cols == 'Seattle, WA': ax.set_ylim([0, 1000])\n",
    "    if cols == 'Chico, CA': ax.set_ylim([0, 800])\n",
    "    if cols == 'Stockton, CA': ax.set_ylim([0, 800])\n",
    "\n",
    "\n",
    "    ax.tick_params(axis='both', labelsize=12)\n",
    "        \n",
    "    # Use a more precise date string for the x axis locations in the toolbar.\n",
    "    ax.fmt_xdata = mdates.DateFormatter('%m-%d')\n",
    "    \n",
    "    # Define the date format\n",
    "    date_form = DateFormatter(\"%m-%d\")\n",
    "    ax.xaxis.set_major_formatter(date_form)\n",
    "\n",
    "    # Rotate and align the tick labels so they look better.\n",
    "    fig.autofmt_xdate()\n",
    "# texts\n",
    "fig.text(0.09,0.5, \"CO mixing ratio (ppb)\", ha=\"center\", va=\"center\", rotation=90, fontsize=18)\n",
    "fig.text(0.3,0.91, 'CO daily pattern over western US (WE-CAN)', fontsize=25)\n",
    "fig.savefig('./figure/grd_dailypattern.png')\n",
    "plt.close() #where f is the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae4c08e8-18d0-495b-8846-2ee15bea17b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entire season\n",
    "data_entire = {'MB (base)': np.round(np.array(MB_base_entire),2),\n",
    "               'MB (3 × GFAS)': np.round(np.array(MB_threegfas_entire),2),\n",
    "               'RMSE (base)': np.round(np.array(RMSE_base_entire),2),\n",
    "               'RMSE (3 × GFAS)': np.round(np.array(RMSE_threegfas_entire),2),\n",
    "               'R (base)': np.round(np.array(R_base_entire),2),\n",
    "               'R (3 × GFAS)': np.round(np.array(R_threegfas_entire),2)\n",
    "              }\n",
    "df_entire = pd.DataFrame(data = data_entire, index=site_names)\n",
    "\n",
    "# smoky days\n",
    "data_smoky = {'MB (base)': np.round(np.array(MB_base_smoky),2),\n",
    "               'MB (3 × GFAS)': np.round(np.array(MB_threegfas_smoky),2),\n",
    "               'RMSE (base)': np.round(np.array(RMSE_base_smoky),2),\n",
    "               'RMSE (3 × GFAS)': np.round(np.array(RMSE_threegfas_smoky),2),\n",
    "               'R (base)': np.round(np.array(R_base_smoky),2),\n",
    "               'R (3 × GFAS)': np.round(np.array(R_threegfas_smoky),2)}\n",
    "df_smoky = pd.DataFrame(data = data_smoky, index=site_names)\n",
    "\n",
    "# nonsmoky days\n",
    "data_nonsmoky = {'MB (base)': np.round(np.array(MB_base_nonsmoky),2),\n",
    "               'MB (3 × GFAS)': np.round(np.array(MB_threegfas_nonsmoky),2),\n",
    "               'RMSE (base)': np.round(np.array(RMSE_base_nonsmoky),2),\n",
    "               'RMSE (3 × GFAS)': np.round(np.array(RMSE_threegfas_nonsmoky),2),\n",
    "               'R (base)': np.round(np.array(R_base_nonsmoky),2),\n",
    "               'R (3 × GFAS)': np.round(np.array(R_threegfas_nonsmoky),2)}\n",
    "df_nonsmoky = pd.DataFrame(data = data_nonsmoky, index=site_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "106101a3-fc6d-4b88-80bb-e76bb6f02795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the dataframe\n",
    "df_entire.to_csv('./output_data/grd_timeseries_entire.csv')\n",
    "df_smoky.to_csv('./output_data/grd_timeseries_smoky.csv')\n",
    "df_nonsmoky.to_csv('./output_data/grd_timeseries_nonsmoky.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1047216-e699-4e55-824e-6322b0514320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte background value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10945b6f-44bc-4081-9c8a-0b57f08308cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seattle, WA        -43.958447\n",
       "Boise, ID           57.054892\n",
       "Missoula, MT        18.281254\n",
       "Mt. Bachelor, OR    17.997981\n",
       "Reno, NV            24.567765\n",
       "Denver, CO          31.043563\n",
       "Chico, CA           74.283879\n",
       "Stockton, CA        41.535043\n",
       "Fresno, CA          53.758598\n",
       "Name: 0.05, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_obs_daily.quantile(0.05) - df_mod_CO_base.quantile(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefdd1d1-fbcb-47db-930a-f1c2efdf1d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d408e04-5ad4-4ce4-ab30-c153c134e4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1f020b-0856-4392-a9f6-21ac1a72ff86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4032ea9f-c7a7-44a9-b993-6415b93a12d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccb8bf3-9031-4822-81b1-4aa7917b6491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfa7f6c-3b11-4d47-b470-8c5ff4acc6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e5613-3ad1-45ff-8283-e3f6379dffd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a79c70-e256-41a6-b18e-3d77e641ce13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d324e4d2-eacf-448b-babe-5687265b8337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37c92db-aaff-40d5-b940-0fb74d0fb861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314af6e5-8b61-45ca-89e7-45a6a8dfc240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce70078-236d-4faf-84ba-b958e37d6f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d3aef1-5df0-4ac8-b57a-e5417a1cbc02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a268abf-8a77-4c8b-bbda-45c3d34acbad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6405b731-46ca-4bbe-8bbe-7448086a4ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ebe93f-6d8e-467e-b629-4fd446c35d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e59def-62b3-443b-8560-880b2d99eba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a2164d-8839-4d0a-aada-61ba251f2632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e180b2-ab35-48c3-95dc-94cfff7a96e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d03968e-00c4-4457-a5ed-74bdd7053093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c35fac2-b0d3-4da5-8491-126d96389dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6e4b6b-a2c3-4762-990f-865e34e01ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec0b79b-0283-43b5-8658-40a67a9e4a43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b7c5a5-eb47-4f2b-be82-f8b0e5654ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f255f91-a48a-4cd7-a0ac-a33e7f7a7232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create fl_prx_list\n",
    "# sites\n",
    "sites = ['Seattle','Portland','Boise','Denver','Stockton','Fresno','Reno','Chico','Missoula','MBO']\n",
    "#sites = ['Seattle','Portland']\n",
    "\n",
    "# create normal list\n",
    "fl_prx_list = []\n",
    "num = 0\n",
    "for ss in sites:\n",
    "    num = num + 1\n",
    "    tmp_fl_prx = '/glade/scratch/lixujin/rundirs/GCv13/OutputDir/GEOSChem.SpeciesConcSubset' + str(num) + '.hourly_' + ss + '.'\n",
    "    fl_prx_list.append(tmp_fl_prx)\n",
    "    \n",
    "# define start date and end date\n",
    "strt_dt = datetime.date(2018,7,17)\n",
    "end_dt = datetime.date(2018,8,20)\n",
    "#end_dt =datetime.date(2018,7,18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca893d01-03aa-4466-808a-ecb3a44fae0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_site_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_site_data' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create a empty dataframe\n",
    "df_final = pd.DataFrame()\n",
    "# read in data\n",
    "num = 0\n",
    "for fl_prx in fl_prx_list:\n",
    "    df_tmp = get_site_data(fl_prx, strt_dt, end_dt)\n",
    "    df_final = pd.concat([df_final, df_tmp], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0ecbd9-b055-4fcb-a49c-d315e4173943",
   "metadata": {},
   "source": [
    "Process data before analyzing it may save some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "702f154a-4b96-4684-aa24-ade3bcf9fc3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Seattle', 'MBO', 'Reno', 'Fresno', 'Stockton', 'Chico', 'Denver',\\n       'Boise', 'Missoula'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-d164da0955ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Reorder columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Seattle'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'MBO'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Reno'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Fresno'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Stockton'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Chico'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Denver'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Boise'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Missoula'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# rename columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m new_names_dict = {'Seattle':'Seattle, WA', \n",
      "\u001b[0;32m~/work/anaconda3/envs/gcpy/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2984\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2986\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/anaconda3/envs/gcpy/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1283\u001b[0m                 \u001b[0;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"raise_missing\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/anaconda3/envs/gcpy/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1092\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m         )\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/anaconda3/envs/gcpy/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 raise KeyError(\n\u001b[1;32m   1176\u001b[0m                     \"None of [{key}] are in the [{axis}]\".format(\n\u001b[0;32m-> 1177\u001b[0;31m                         \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m                     )\n\u001b[1;32m   1179\u001b[0m                 )\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Seattle', 'MBO', 'Reno', 'Fresno', 'Stockton', 'Chico', 'Denver',\\n       'Boise', 'Missoula'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Reorder columns\n",
    "df_final = df_final[['Seattle','MBO','Reno','Fresno','Stockton','Chico','Denver','Boise','Missoula']]\n",
    "df_final.head(10)\n",
    "# rename columns\n",
    "new_names_dict = {'Seattle':'Seattle, WA', \n",
    "                  'MBO': 'Mt.Bachelor, OR', \n",
    "                  'Reno': 'Reno, NV', \n",
    "                  'Fresno': 'Fresno, CA',\n",
    "                  'Stockton': 'Stockton, CA',\n",
    "                  'Chico':'Chico, CA',\n",
    "                  'Denver': 'Denver, CO',\n",
    "                  'Boise': 'Boise, ID',\n",
    "                  'Missoula': 'Missoula, MT'}\n",
    "df_mod_diurnal = df_final.rename(columns = new_names_dict, inplace=False) #Set inplace eq 1 then the old column names will be replaced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2968a4e0-812f-450e-aa3f-aeb614c02654",
   "metadata": {},
   "source": [
    "##### Save model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed2ceeb-b8de-4177-91f3-142a5463897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/glade/work/lixujin/PYTHON/PROJECT/WE-CAN/df_diurnal_mod.csv'\n",
    "df_mod_diurnal.to_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfd7880-f06f-43f5-8c5f-360d9bf59bef",
   "metadata": {},
   "source": [
    "##### read prepared model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9ffed5-b7e1-4da1-bb89-118077ce3151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in csv data\n",
    "import pandas as pd\n",
    "df_mod_diurnal = pd.read_csv(file,index_col=0)#,header=0,index_col=0)\n",
    "df_mod_diurnal.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0315dbb-56fd-419d-be29-91ab755e6219",
   "metadata": {},
   "source": [
    "##### Do the plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf512c54-103c-48c1-a634-8ffab1844cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "fig, axes = plt.subplots(3, 3, figsize=(20,18),sharex=True)\n",
    "for cols, ax in zip(df_obs.columns[1:], axes.flatten()):\n",
    "    ax.plot(df_obs['DDHH GMT'], df_obs[cols])\n",
    "    # Spacing Out\n",
    "    plt.subplots_adjust(wspace=.10, hspace=.10)\n",
    "    ax.set_title(cols) #Seattle, WA; Mt.Bachelor, OR; Reno, NV; Fresno, CA; Stockton, CA; Chico, CA; Denver, CO; Boise, ID; Missoula, MT \n",
    "    \n",
    "    # Rotate and align the tick labels so they look better.\n",
    "    fig.autofmt_xdate()\n",
    "    # Use a more precise date string for the x axis locations in the toolbar.\n",
    "    ax.fmt_xdata = mdates.DateFormatter('%Y-%m-%d')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63accc7e-1f01-4474-96e8-b999ce3fbed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily pattern plot\n",
    "fig, axes = plt.subplots(3, 3, figsize=(24,18),sharex=True)\n",
    "for cols, ax in zip(df_obs_daily.columns, axes.flatten()):\n",
    "    ax.plot(df_obs_daily.index, df_obs_daily[cols])\n",
    "    \n",
    "    # Spacing Out\n",
    "    plt.subplots_adjust(wspace=.10, hspace=.10)\n",
    "\n",
    "    #Seattle, WA; Mt.Bachelor, OR; Reno, NV; Fresno, CA; Stockton, CA; Chico, CA; Denver, CO; Boise, ID; Missoula, MT \n",
    "    ax.set_title(cols) \n",
    "    \n",
    "    # Rotate and align the tick labels so they look better.\n",
    "    fig.autofmt_xdate()\n",
    "    # Use a more precise date string for the x axis locations in the toolbar.\n",
    "    ax.fmt_xdata = mdates.DateFormatter('%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdea625a-f1ca-452a-88e9-814dbc358e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379a9a73-9578-408a-bdad-c89c9f7f281f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diurnal pattern plot\n",
    "fig, axes = plt.subplots(3, 3, figsize=(24,20),sharex=True)\n",
    "for cols, ax in zip(df_obs_diurnal.columns, axes.flatten()):\n",
    "    ax.plot(df_obs_diurnal.index, df_obs_diurnal[cols])\n",
    "    ax.plot(df_mod_diurnal.index, df_mod_diurnal[cols])\n",
    "\n",
    "    # Spacing Out\n",
    "    plt.subplots_adjust(wspace=.10, hspace=.10)\n",
    "    ax.set_title(cols) #Seattle, WA; Mt.Bachelor, OR; Reno, NV; Fresno, CA; Stockton, CA; Chico, CA; Denver, CO; Boise, ID; Missoula, MT \n",
    "    \n",
    "    # Rotate and align the tick labels so they look better.\n",
    "    fig.autofmt_xdate()\n",
    "    # Use a more precise date string for the x axis locations in the toolbar.\n",
    "    ax.fmt_xdata = mdates.DateFormatter('%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf19039-0ddd-4baa-811a-8aed628678af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593fc8c7-a20f-4417-9cd1-c292747a7435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-ministry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-vaccine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a0e5ba-452a-4a51-b9a6-e80a8262ed17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26a9825-2d04-4c10-9960-ca6651da7b09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0e498a-9b78-42b0-aae6-bf80427aa6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d8d8d6-d427-40b9-878f-1088182d9d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d2cb20-3119-4f71-b8e8-c6dc797b239d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40963bbb-f71a-47fe-9189-522b86e52c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d5c016-73ff-4967-b339-8a2d61f00e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea54e64-5355-47f3-b116-1cfda2aa8bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4c29ca-8805-4f15-8402-19c1ee2e36c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a32a6b2-6a8a-4931-b76d-a7c53a3976ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377b63f3-e3c3-4441-b69c-9cdcb5156e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf14ef0-5ef8-458f-9e4c-6886b86699a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e13419-a849-417b-889b-541a7c90f306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f0b4c1-eced-40aa-8d94-cca40c40ea58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f59d09-a5a3-4332-bbf9-c7b1ce66c83e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7eaa57-e5e3-49d9-aae0-18144fe3be90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073253a8-9457-4a5b-92dd-b83d6c35bab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b0b007-5253-4e0a-bd2f-d15570541e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80062ed6-47fb-4b9a-b799-0973c1282760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-gcpy]",
   "language": "python",
   "name": "conda-env-anaconda3-gcpy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
